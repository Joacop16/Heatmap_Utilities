{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a476f7-3b50-4c0e-9d4e-fe1c3a3a8396",
   "metadata": {},
   "source": [
    "$$\\textrm{Joaquin Peñuela Parra}$$\n",
    "$$\\textrm{Universidad de los Andes}$$\n",
    "$$\\textrm{Grupo de Física de Altas Energías: Fenomenología de Partículas}$$\n",
    "\n",
    "$\\textbf{Preliminaries}$ \n",
    "\n",
    "The libraries used here are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7046cca2-7888-4471-8b89-3f16afd08f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51bf9ee-6f45-441f-ab4a-38d661f2fac5",
   "metadata": {},
   "source": [
    "This jupyter notebook defines python functions that facilitate the analysis of heatmaps associated with DataFrames stored in Excel files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50673738-82cd-46b1-bde8-25abb2c3a88c",
   "metadata": {},
   "source": [
    "$\\textbf{Functions}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38c1aa4-fe4e-45f5-afd2-450d9a4ebe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel(path, index_colum = 0):\n",
    "    '''This function receives a path to an excel file and returns the DataFrame contained.\n",
    "    \n",
    "    Parameters:\n",
    "    - path*: excel file path (file ending in .xlsx).\n",
    "    - index_colum: column of the table that contains the indexes of the DataFrame (by default it is column 0).\n",
    "    \n",
    "    Return:\n",
    "    - data: Pandas DataFrame.\n",
    "    '''\n",
    "\n",
    "    data = pd.read_excel(path, index_col = index_colum)\n",
    "    data.sort_index(level=0, ascending=False, inplace=True)\n",
    "    data.columns = [float(i) for i in data.columns]\n",
    "    data.index = [float(i) for i in data.index]  \n",
    "    \n",
    "    return data\n",
    "\n",
    "def read_csv(path, index_colum = 0):\n",
    "    '''This function receives a path to an csv file and returns the DataFrame contained.\n",
    "    \n",
    "    Parameters:\n",
    "    - path*: csv file path (file ending in .csv).\n",
    "    - index_colum: column of the table that contains the indexes of the DataFrame (by default it is column 0).\n",
    "    \n",
    "    Return:\n",
    "    - data: Pandas DataFrame.\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(path, index_col = index_colum)\n",
    "    data.sort_index(level=0, ascending=False, inplace=True)\n",
    "    data.columns = [float(i) for i in data.columns]\n",
    "    data.index = [float(i) for i in data.index]  \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca5ece02-15fd-4010-9ab4-017c2f548ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(Data, log = False):\n",
    "    \n",
    "    '''This function receives an array of data and interpolates the data to re-turn a larger and \"continuous\" DataFrame.\n",
    "        \n",
    "    Parameters:\n",
    "    - Data*: DataFrame with the data, each entry refers to the value of a variable based on the column and row values. For example, if we consider two independent variables A, B and a function F(A,B), Data is a matrix where the rows take the values of A and the columns the values of B, i.e. each entry in the matrix will be just F(A,B).    \n",
    "    - log: Boolean that says if we will work with logarithmic scale (base 10).\n",
    "\n",
    "    Return:\n",
    "    - Data_interpolated: Pandas DataFrame.\n",
    "    '''\n",
    "    \n",
    "    index = Data.index #DataFrame row labels\n",
    "    columns = Data.columns #DataFrame column labels\n",
    "        \n",
    "    if log: Data = np.log10(Data)\n",
    "    \n",
    "    #In order to apply griddata (scipy function that allows interpolation) it is necessary to rewrite the data of a matrix in a three-column format. Instead of having a matrix where the function is evaluated according to the row and column, it is better to rewrite everything in a three column format. Simply: A, B, F(A,B). This is what the following code does:    \n",
    "    \n",
    "    matrix = np.zeros([len(columns)*len(index),3])\n",
    "    column_0 = []\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(len(index)):\n",
    "            column_0.append(columns[i])\n",
    "\n",
    "    column_1 = []\n",
    "    for j in range(len(columns)):\n",
    "        for i in range(len(index)):\n",
    "            column_1.append(index[i])\n",
    "\n",
    "    matrix[:,0] = column_0\n",
    "    matrix[:,1] = column_1\n",
    "\n",
    "    for k in range(len(matrix[:,2])):\n",
    "        matrix[k,2] = Data[matrix[k,0]][matrix[k,1]]\n",
    "\n",
    "    Data = pd.DataFrame(matrix) \n",
    "    Data.columns = [\"A\", \"B\", \"F(A,B)\"] #Three-column format\n",
    "    \n",
    "    #At this point, the data can be easily read, now what must be done is to create the values ​​of x that we want to interpolate, that is, the continuous intervals that we want to interpolate, I will call these \"x\" and \"y\". However, the case in which one variable is fixed and only the other takes different values ​​must be taken into account, this is what the len(--) == 1 represent:\n",
    "\n",
    "    if(len(columns) == 1): x = columns \n",
    "    else: x = np.linspace(np.min(Data['A']),np.max(Data['A']),500) \n",
    "    \n",
    "    if(len(index) == 1): y = index \n",
    "    else: y = np.linspace(np.min(Data['B']),np.max(Data['B']),500) \n",
    "    \n",
    "    #At this point we already have \"x\" and \"y\", now we must combine them to take into account all the combinations, this is done by np.meshgrid:   \n",
    "    gridx, gridy = np.meshgrid(x,y)\n",
    "    \n",
    "    #Finally, it would be enough to interpolate using our data as a base; However, three cases must be taken into account:\n",
    "    \n",
    "    if (len(columns) == 1):\n",
    "        Data_interpolated = griddata(Data['B'].values, Data['F(A,B)'].values, y, method='cubic') \n",
    "        Data_interpolated = pd.DataFrame(Data_interpolated)           \n",
    "        Data_interpolated.index = y\n",
    "        Data_interpolated.columns = x\n",
    "        Data_interpolated.columns = [round(i,2) for i in Data_interpolated.columns]\n",
    "        Data_interpolated.index = [round(i,2) for i in Data_interpolated.index] \n",
    "        \n",
    "    elif (len(index) == 1):\n",
    "        Data_interpolated = griddata(Data['A'].values, Data['F(A,B)'].values, x , method='cubic') \n",
    "        Data_interpolated = pd.DataFrame(Data_interpolated)\n",
    "        Data_interpolated.index = x\n",
    "        Data_interpolated.columns = y\n",
    "        Data_interpolated = Data_interpolated.T #griddata always returns in the form of a column vector, but if in this case and it is fixed, our data must be in a row vector format, that does the .T, it takes out the transpose.\n",
    "        Data_interpolated.columns = [round(i,2) for i in Data_interpolated.columns]\n",
    "        Data_interpolated.index = [round(i,2) for i in Data_interpolated.index] \n",
    "        \n",
    "    else:\n",
    "        Data_interpolated = griddata((Data['A'].values,Data['B'].values), Data['F(A,B)'].values, (gridx,gridy), method='cubic')\n",
    "        Data_interpolated = pd.DataFrame(Data_interpolated)\n",
    "        Data_interpolated.index = y\n",
    "        Data_interpolated.columns = x\n",
    "            \n",
    "    Data_interpolated.sort_index(level=0, ascending=False, inplace=True) #Allows the graph to show the y-axis growing upwards\n",
    "    \n",
    "    return Data_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c2a505-def5-43a9-a966-988d408e5323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(Data, level_curves = {}, level_curves_labels_locations = [], zoom_region = {}, **kwargs):\n",
    "\n",
    "    '''This function plots the heat map of a DataFrame. In addition to this, it also plots contour lines and zoom_regions if the user wants it.\n",
    "    \n",
    "    Parameters:\n",
    "    - level_curves: Directory containing the level curves to be ploted. It must have the structure {value (float): label(string),...}.\n",
    "    - level_curves_labels_locations: List with suggested coordinates [(x1,y1), (x2,y2),...] of the positions where you want the signs of each level curve to be: The order does not matter.\n",
    "    - zoom_region: Directory containing the positions to be zoom_regioned. It must have the structure {x1 (string): value (float), x2 (string): value (float), y1 (string): value (float), y2 (string): value (float),}.\n",
    "    - **kwargs: Optional parameters like title, title_right, title_left, x_label, y_label, cbar_label, color, File_name, etc.\n",
    "    \n",
    "    Return:\n",
    "    - fig, ax, curves: matplotlib.pyplot subplots and contours.\n",
    "    '''\n",
    "    \n",
    "    curves = 0\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    try: plt.title(kwargs['title'])\n",
    "    except: pass\n",
    "\n",
    "    try: plt.title(kwargs['title_right'], loc = 'right')\n",
    "    except: pass\n",
    "\n",
    "    try: plt.title(kwargs['title_left'], loc = 'left')\n",
    "    except: pass\n",
    "\n",
    "    try: x_label = kwargs['x_label']\n",
    "    except: x_label = ''\n",
    "\n",
    "    try: y_label = kwargs['y_label']\n",
    "    except: y_label = ''\n",
    "\n",
    "    try: cbar_label = kwargs['cbar_label']\n",
    "    except: cbar_label = ''\n",
    "    \n",
    "    try: color = kwargs['color']\n",
    "    except: color = 'viridis'\n",
    "    \n",
    "    try: File_name = kwargs['File_name']\n",
    "    except: File_name = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    index = Data.index\n",
    "    columns = Data.columns\n",
    "    \n",
    "    if(len(index) == 1 or len(columns) == 1):\n",
    "        Data.sort_index(level=0, ascending=False, inplace=True) \n",
    "        sns.heatmap(Data, cmap = color, cbar_kws={'label': cbar_label}).set(xlabel= x_label, ylabel= y_label)\n",
    "        \n",
    "    else:\n",
    "        mapa_calor = plt.pcolormesh(columns, index, Data.values, cmap = color)\n",
    "        plt.colorbar(mapa_calor, label = cbar_label)  \n",
    "    \n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "    \n",
    "    #Depending on the shape of the data, the curves are plotted differently. In the event that one of the two independent variables is fixed, then the matplotlib contour function cannot be used due to the dimension of said variable. In that case, it is necessary to plot asymptotes .\n",
    "    \n",
    "    if (len(list(level_curves.keys())) != 0):\n",
    "\n",
    "        index = Data.index\n",
    "        columns = Data.columns\n",
    "\n",
    "        if(len(index) == 1):\n",
    "            linestyles = ['-', '--', '-.', ':', '']\n",
    "            for i in range(len(list(level_curves.keys()))):\n",
    "                curva = list(level_curves.keys())[i]\n",
    "                indice = np.abs(np.asarray(Data - curva)).argmin()\n",
    "                \n",
    "                #It is plotted with the sign inside the plot:\n",
    "                ax.axvline(indice, ls = linestyles[1], color = 'white') \n",
    "                ax.text(indice - 20, 0.5, level_curves[curva], rotation = 90, color = 'white')\n",
    "                \n",
    "                #It is plotted with the sign in a legend\n",
    "                #ax.axvline(indice, label = level_curves[curva], ls = linestyles[i % 5], color = 'white') \n",
    "            # ax.legend()\n",
    "\n",
    "        elif(len(columns) == 1):\n",
    "            \n",
    "            linestyles = ['-', '--', '-.', ':', '']\n",
    "            for i in range(len(list(level_curves.keys()))):\n",
    "                curva = list(level_curves.keys())[i]\n",
    "                indice = np.abs(np.asarray(Data - curva)).argmin()\n",
    "                \n",
    "                #It is plotted with the sign inside the plot:\n",
    "                ax.axhline(indice, ls = linestyles[1], color = 'white') \n",
    "                ax.text(0.5, indice + 20 , level_curves[curva], color = 'white')\n",
    "                \n",
    "                #It is plotted with the sign in a legend\n",
    "                #ax.axhline(indice, label = level_curves[curva], ls = linestyles[i % 5], color = 'white')\n",
    "            #ax.legend()\n",
    "            \n",
    "        else:\n",
    "            curves = plt.contour(Data.columns, Data.index, Data.values, levels = list(sorted(level_curves.keys())), colors = ['white'], linestyles = 'dashed') #Level curves\n",
    "            if (len(level_curves_labels_locations) != 0): ax.clabel(curves, curves.levels, manual = level_curves_labels_locations, fmt = level_curves, fontsize=10, rightside_up = True) #Labels level curves location\n",
    "            else: ax.clabel(curves, curves.levels, inline=True, fmt = level_curves, fontsize=10, rightside_up = True) #Labels level curves\n",
    "\n",
    "    if (len(list(zoom_region.keys())) != 0):\n",
    "        \n",
    "        if (len(index) == 1 or len(columns) == 1): print('It is not possible to zoom_region due to the dimensions of the DataFrame.')\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            ax_zoom = ax.inset_axes([1.4, 0, 1, 1])\n",
    "            \n",
    "            ax_zoom.pcolormesh(Data.columns, Data.index, Data.values, cmap = color)\n",
    "            \n",
    "            if (len(list(level_curves.keys())) != 0): ax_zoom.contour(Data.columns, Data.index, Data.values, levels = list(sorted(level_curves.keys())), colors = ['white'], linestyles = 'dashed') #Curvas de nivel\n",
    "\n",
    "            ax_zoom.set_xlim(zoom_region['x1'], zoom_region['x2'])\n",
    "            ax_zoom.set_ylim(zoom_region['y1'], zoom_region['y2'])\n",
    "            ax_zoom.set_xlabel(x_label)\n",
    "            ax_zoom.set_ylabel(y_label)\n",
    "\n",
    "            ax.indicate_inset_zoom(ax_zoom, edgecolor= \"black\")\n",
    "            \n",
    "    if (File_name != ''): plt.savefig(File_name, bbox_inches='tight')\n",
    "    \n",
    "    return fig, ax, curves"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
